<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A few thoughts you're free to ignore"><link rel="shortcut icon" href=https://randthoughts.github.io/favicon.ico><link rel=stylesheet href=/css/style.min.css><title>Simulating memory load with fio</title></head><body><header id=banner><h2><a href=https://randthoughts.github.io/>Random thoughts</a></h2><nav><ul><li><a href=/about/ title=About>about</a></li></ul></nav><div id=description>A few thoughts you're free to ignore</div></header><main id=content><article><header id=post-header><h1>Simulating memory load with fio</h1><div><time>August 20, 2022</time></div></header><p>Recently at work I was tasked with simulating the workload of a client&rsquo;s infrastructure consisting of several virtual machines. For our use case, this turned out to be a largely solved problem, thanks to existing tools like <a href=https://fio.readthedocs.io/en/latest/fio_man.html>fio</a>.</p><p>For those who don&rsquo;t know it, fio is a simple yet powerful program that allows simulating various kinds of I/O workloads. Its simplicity stems from two basic facts: (1) it&rsquo;s a standalone, CLI executable and (2) it uses plain INI files to define workloads. It&rsquo;s also powerful because of its extensibility: thanks to I/O engines, it&rsquo;s not limited to just I/O simulation.</p><p>For example, here&rsquo;s what a CPU-bound workload could look like, using the <code>cpuio</code> engine:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-ini data-lang=ini><span style=display:flex><span><span style=color:#75715e># File: burn-my-cpu.fio</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>[burn-my-cpu]</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Don&#39;t transfer any data, just burn CPU cycles </span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>ioengine</span><span style=color:#f92672>=</span><span style=color:#e6db74>cpuio</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Load the CPU at 100%</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>cpuload</span><span style=color:#f92672>=</span><span style=color:#e6db74>100</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Make four clones of this job. In a multiprocessor system, </span>
</span></span><span style=display:flex><span><span style=color:#75715e># these are run concurrently on multiple CPUs.</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>numjobs</span><span style=color:#f92672>=</span><span style=color:#e6db74>4</span>
</span></span></code></pre></div><p>You can run it with the command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>fio burn-my-cpu.fio
</span></span></code></pre></div><p>The interesting thing here&mdash;beyond the fact that we&rsquo;re stressing the <em>CPU</em> with an I/O simulation tool&mdash;is <code>numjobs=4</code>, which instructs fio to fork four processes&mdash;or rather, <em>jobs</em>, in fio lingo&mdash;executing the same workload. One could also play with the reserved variable <code>$ncpus</code> to load the desired number of CPUs based on the system at hand.</p><p>OK, so fio is capable of generating both I/O and CPU workloads. What about memory? Specifically, how can we simulate a certain amount of memory being allocated for a period of time? Note that here I&rsquo;m not interested in the simulation of specific read/write patterns; if that&rsquo;s the case for you, time to close this browser tab I guess.</p><p>After a bit of trial and error, I came up with the solution below. I&rsquo;m not saying that it&rsquo;s perfect or the right way to do it, but according to my testsâ„¢ it does the job:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-ini data-lang=ini><span style=display:flex><span><span style=color:#75715e># File: fill-my-memory.fio</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>[fill-my-memory]</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This may be omitted, as it&#39;s already the default</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>ioengine</span><span style=color:#f92672>=</span><span style=color:#e6db74>psync</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Just read, don&#39;t write anything</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>readwrite</span><span style=color:#f92672>=</span><span style=color:#e6db74>read</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Read from /dev/zero to avoid disk I/O</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>filename</span><span style=color:#f92672>=</span><span style=color:#e6db74>/dev/zero</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Read 1GiB into memory</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>size</span><span style=color:#f92672>=</span><span style=color:#e6db74>1g</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Pin 1GiB of memory with mlock(2)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This prevents memory from being paged to the swap area</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>lockmem</span><span style=color:#f92672>=</span><span style=color:#e6db74>1g</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Normally, once the specified size is read, the job terminates</span>
</span></span><span style=display:flex><span><span style=color:#75715e># To keep it running, we set the run time explicitly</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>time_based</span><span style=color:#f92672>=</span><span style=color:#e6db74>1</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>runtime</span><span style=color:#f92672>=</span><span style=color:#e6db74>5m</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Stall the job after it has finished reading 1GiB</span>
</span></span><span style=display:flex><span><span style=color:#75715e># This avoids wasting CPU cycles</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>thinktime</span><span style=color:#f92672>=</span><span style=color:#e6db74>1s</span>
</span></span></code></pre></div><p>Don&rsquo;t worry, I&rsquo;ll try to explain everything in a moment (if comments haven&rsquo;t already).</p><p>Starting from the top, the I/O engine used is <code>psync</code>, for the simple reason that it happens to be the default (in fact, we can even omit that line in the INI file). And since it appears to be a good fit for our use case, I didn&rsquo;t feel the need to change it. If you&rsquo;re concerned about what <code>psync</code> actually does, you may want to look at <code>pread(2)</code>&rsquo;s man page, since that&rsquo;s what <code>psync</code> leverages behind the scenes. Here&rsquo;s an excerpt:</p><blockquote><p>pread() reads up to count bytes from file descriptor fd at offset (from the start of the file) into the buffer starting at buf.</p></blockquote><p>So far, so good.</p><p>The line <code>readwrite=read</code> tells fio the type of I/O we want to perform. Because we just want to allocate memory, it makes sense to simply <em>read</em> data into it. This is the default behavior, but sometimes explicit is better than implicit<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><p>Now come the interesting bits. First, there&rsquo;s <code>filename=/dev/zero</code>, which is a bit of a hack to avoid reading from a real file stored on disk. Not a big deal, but since we&rsquo;re interested in just allocating a bunch of memory, why doing I/O at all? Especially if we can easily avoid it.</p><p>Then, we use a combination of <code>size=1g</code> and <code>lockmem=1g</code> to read 1GiB worth of zeros into memory <em>and</em> keep that allocated. The need for <code>lockmem</code> can be understood by running the same job <em>without</em> <code>lockmem</code> and inspecting its memory usage, perhaps with <code>top</code> (you may need to tweak its configuration to display the relevant columns). The following figure highlights memory usage when <code>lockmem</code> is <em>not</em> used:</p><figure><img src=/images/without-lockmem.png alt="Memory usage without lockmem."><figcaption>Memory usage without <tt>lockmem</tt>.</figcaption></figure><p>Not all memory is created equal: here we&rsquo;re interested in the value of the <code>RES</code> column, which stands for <em>resident memory</em>. This value refers to the actual, <em>physical</em> memory being allocated to the process, not counting swap. But how can it be (nearly) zero? I&rsquo;m not super knowledgeable about the details, but generally speaking, what is happening here is that even though we are requesting to read 1GiB of data into memory, that amount is not wholly loaded into <em>physical</em> memory. Instead, the OS acts as a middleman by effectively loading a fraction of it.</p><p>You may appreciate why this default behavior is a good thing for everyone; think about what would happen if every process was able to allocate physical memory at will. Not incidentally, the use of <code>lockmem</code> requires root privileges.</p><p>Under the hood, <code>lockmem</code> makes use of the <code>mlock()</code> system call. Once again, <code>man</code> comes to the rescue:</p><blockquote><p>mlock() [&mldr;] lock[s] part or all of the calling process&rsquo;s virtual address space into RAM, preventing that memory from being paged to the swap area.</p></blockquote><p>What <code>lockmem</code> essentially does is &ldquo;pinning&rdquo; the specified amount of memory to the physical memory. Indeed, if we run the job with <code>lockmem=1g</code>, we can see that this time the <code>RES</code> column reports the expected value:</p><figure><img src=/images/with-lockmem.png alt="Memory usage with lockmem."><figcaption>Memory usage with <tt>lockmem</tt>.</figcaption></figure><p>We then have <code>time_based=1</code> and <code>runtime=5m</code>, which simply say: <em>&ldquo;Run this job for five minutes, whether or not we&rsquo;re done with I/O work&rdquo;</em>. Seems innocuous, right? Indeed, it does what we expect, but with a caveat: the CPU goes crazy for the entire job duration.</p><p>As with the unnecessary disk I/O&mdash;which we avoided by reading from <code>/dev/zero</code>&mdash;I didn&rsquo;t like the fact that a job intended to stress the memory generated a substantial amount of CPU workload. I think it&rsquo;s good to keep things isolated so that we can test them independently.</p><p>After digging a bit in fio&rsquo;s manual, my attention was drawn to the description of the <code>time_based</code> parameter:</p><blockquote><p>If set, fio will run for the duration of the runtime specified even if the file(s) are completely read or written. <strong>It will simply loop over the same workload as many times as the runtime allows.</strong></p></blockquote><p>If I understand it correctly, the job is busy reading from <code>/dev/zero</code> over and over, even after the initial read of 1GiB is complete. This inevitably puts a toll on the CPU.</p><p>Fortunately, fio is a goldmine of parameters. In the last line of our workload definition, there&rsquo;s this option called <code>thinktime</code>, which, according to the manual, allows to <em>&ldquo;stall a job for the specified period of time after an I/O has completed before issuing the next&rdquo;</em>. I discovered that setting <code>thinktime</code> to <em>any</em> value that is <em>not</em> in microseconds, causes the job to stall <em>indefinitely</em>&mdash;unless <code>time_based</code> and <code>runtime</code> are also set, in which case the job is stopped after a fixed interval. While this is exactly what <em>we</em> want, I&rsquo;m not sure why fio behaves like that. Even if we agree that <code>thinktime</code> should stall the job indefinitely&mdash;because there&rsquo;s no job to issue next&mdash;why should the chosen unit of time matter?</p><p>Anyway, here&rsquo;s an interesting comparison between the job running without and with <code>thinktime</code> set:</p><figure><img src=/images/cpu-without-thinktime.png alt="CPU and memory usage without thinktime"><figcaption>CPU and memory usage without <tt>thinktime</tt>.</figcaption></figure><figure><img src=/images/cpu-with-thinktime.png alt="CPU and memory usage with thinktime"><figcaption>CPU and memory usage with <tt>thinktime=1s</tt>.</figcaption></figure><p>For the purpose of this visualization, I set <code>runtime=30s</code> and <code>size=4g</code>. You can see that with <code>thinktime=1s</code>, the CPU is doing a significant amount of work only at the beginning and at the end of the job runtime, presumably because it&rsquo;s busy loading/unloading data to/from memory.</p><p>Ouch! Seems we&rsquo;ve hit EOF. Don&rsquo;t forget to run fio as root, because <code>lockmem</code> needs it. I hope this post brought something new to the table!</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p><a href=https://peps.python.org/pep-0020/#the-zen-of-python>https://peps.python.org/pep-0020/#the-zen-of-python</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></article></main><footer id=footer></footer></body></html>